{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clothing Image Prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3qcDcP2capt"
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WIFUk-5wqTE",
        "outputId": "28d7c847-bb01-4dc4-8df4-02e0e33deebc"
      },
      "source": [
        "(X_train,y_train),(X_test,y_test)=fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PEnRhQAAl6w",
        "outputId": "e38e8345-21a9-4819-e12f-3aee92adef49"
      },
      "source": [
        "print (\"Number of samples/observations in training data: \" + str(len(X_train)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples/observations in training data: 60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "s5Ox5tcbw4-h",
        "outputId": "2a66d58a-d32a-48e8-b9b4-8fa0cf1f80c1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.subplot(231)\n",
        "random_num=np.random.randint(0,len(X_train))\n",
        "plt.imshow(X_train[random_num],cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(232)\n",
        "random_num=np.random.randint(0,len(X_train))\n",
        "plt.imshow(X_train[random_num],cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(233)\n",
        "random_num=np.random.randint(0,len(X_train))\n",
        "plt.imshow(X_train[random_num],cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(234)\n",
        "random_num=np.random.randint(0,len(X_train))\n",
        "plt.imshow(X_train[random_num],cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(235)\n",
        "random_num=np.random.randint(0,len(X_train))\n",
        "plt.imshow(X_train[random_num],cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkK-Oc2Ewj2i",
        "outputId": "cc0730e8-cf52-437b-c7da-17cf42484632"
      },
      "source": [
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization\n",
        "from keras import backend as K\n",
        "Batch_size = 128\n",
        "epochs=100\n",
        "img_rows=X_train[0].shape[0]\n",
        "img_columns=X_train[1].shape[0]\n",
        "X_train=X_train.reshape(X_train.shape[0],img_rows,img_columns,1)\n",
        "X_test=X_test.reshape(X_test.shape[0],img_rows,img_columns,1)\n",
        "input_shape = (img_rows,img_columns,1)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train/=255\n",
        "X_test/=255\n",
        "y_train=np_utils.to_categorical(y_train)\n",
        "y_test=np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "num_pixels= X_train.shape[1]*X_train.shape[2]\n",
        "model=Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64,kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,200,778\n",
            "Trainable params: 1,200,330\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHyksb5G-EV8",
        "outputId": "058fa1c0-7297-400d-9ce9-c1eb74f269bf"
      },
      "source": [
        "model_fitting=model.fit(X_train,y_train,batch_size=Batch_size,epochs=epochs,verbose=1,validation_data=(X_test,y_test))\n",
        "score=model.evaluate(X_test,y_test,verbose=0)\n",
        "print('Test_loss',score[0])\n",
        "print('Test_accuracy',score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 51s 12ms/step - loss: 3.0811 - accuracy: 0.1798 - val_loss: 1.5187 - val_accuracy: 0.4861\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 1.6721 - accuracy: 0.4634 - val_loss: 0.8542 - val_accuracy: 0.7037\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 1.2825 - accuracy: 0.5852 - val_loss: 0.7380 - val_accuracy: 0.7392\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 1.1002 - accuracy: 0.6452 - val_loss: 0.6750 - val_accuracy: 0.7606\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 1.0019 - accuracy: 0.6740 - val_loss: 0.6325 - val_accuracy: 0.7727\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.9226 - accuracy: 0.6983 - val_loss: 0.6029 - val_accuracy: 0.7816\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.8726 - accuracy: 0.7116 - val_loss: 0.5781 - val_accuracy: 0.7903\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.8351 - accuracy: 0.7241 - val_loss: 0.5600 - val_accuracy: 0.7979\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.7951 - accuracy: 0.7335 - val_loss: 0.5429 - val_accuracy: 0.8044\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.7792 - accuracy: 0.7406 - val_loss: 0.5309 - val_accuracy: 0.8094\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.7409 - accuracy: 0.7504 - val_loss: 0.5202 - val_accuracy: 0.8120\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.7370 - accuracy: 0.7521 - val_loss: 0.5090 - val_accuracy: 0.8168\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.7092 - accuracy: 0.7616 - val_loss: 0.5001 - val_accuracy: 0.8205\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6943 - accuracy: 0.7668 - val_loss: 0.4920 - val_accuracy: 0.8231\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6837 - accuracy: 0.7695 - val_loss: 0.4838 - val_accuracy: 0.8265\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6609 - accuracy: 0.7756 - val_loss: 0.4769 - val_accuracy: 0.8290\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6569 - accuracy: 0.7781 - val_loss: 0.4706 - val_accuracy: 0.8317\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6475 - accuracy: 0.7791 - val_loss: 0.4650 - val_accuracy: 0.8325\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6426 - accuracy: 0.7832 - val_loss: 0.4603 - val_accuracy: 0.8351\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6340 - accuracy: 0.7873 - val_loss: 0.4549 - val_accuracy: 0.8381\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6153 - accuracy: 0.7914 - val_loss: 0.4499 - val_accuracy: 0.8397\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6029 - accuracy: 0.7942 - val_loss: 0.4457 - val_accuracy: 0.8419\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6118 - accuracy: 0.7948 - val_loss: 0.4413 - val_accuracy: 0.8438\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5886 - accuracy: 0.7992 - val_loss: 0.4376 - val_accuracy: 0.8456\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5881 - accuracy: 0.8002 - val_loss: 0.4345 - val_accuracy: 0.8473\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5784 - accuracy: 0.8038 - val_loss: 0.4302 - val_accuracy: 0.8481\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5772 - accuracy: 0.8036 - val_loss: 0.4269 - val_accuracy: 0.8491\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5729 - accuracy: 0.8029 - val_loss: 0.4234 - val_accuracy: 0.8518\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5648 - accuracy: 0.8073 - val_loss: 0.4213 - val_accuracy: 0.8521\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5547 - accuracy: 0.8104 - val_loss: 0.4185 - val_accuracy: 0.8536\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5553 - accuracy: 0.8120 - val_loss: 0.4157 - val_accuracy: 0.8548\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5434 - accuracy: 0.8154 - val_loss: 0.4129 - val_accuracy: 0.8556\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5389 - accuracy: 0.8176 - val_loss: 0.4111 - val_accuracy: 0.8554\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5394 - accuracy: 0.8150 - val_loss: 0.4077 - val_accuracy: 0.8568\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5371 - accuracy: 0.8165 - val_loss: 0.4055 - val_accuracy: 0.8579\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5346 - accuracy: 0.8162 - val_loss: 0.4033 - val_accuracy: 0.8574\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5337 - accuracy: 0.8200 - val_loss: 0.4010 - val_accuracy: 0.8586\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5269 - accuracy: 0.8197 - val_loss: 0.3987 - val_accuracy: 0.8596\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5188 - accuracy: 0.8228 - val_loss: 0.3964 - val_accuracy: 0.8605\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5158 - accuracy: 0.8259 - val_loss: 0.3943 - val_accuracy: 0.8608\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5099 - accuracy: 0.8257 - val_loss: 0.3926 - val_accuracy: 0.8607\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5061 - accuracy: 0.8263 - val_loss: 0.3917 - val_accuracy: 0.8619\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.5057 - accuracy: 0.8270 - val_loss: 0.3893 - val_accuracy: 0.8630\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4979 - accuracy: 0.8304 - val_loss: 0.3873 - val_accuracy: 0.8637\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4966 - accuracy: 0.8307 - val_loss: 0.3856 - val_accuracy: 0.8642\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4947 - accuracy: 0.8290 - val_loss: 0.3843 - val_accuracy: 0.8649\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4937 - accuracy: 0.8304 - val_loss: 0.3828 - val_accuracy: 0.8655\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4815 - accuracy: 0.8342 - val_loss: 0.3812 - val_accuracy: 0.8664\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4769 - accuracy: 0.8383 - val_loss: 0.3793 - val_accuracy: 0.8670\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4854 - accuracy: 0.8344 - val_loss: 0.3783 - val_accuracy: 0.8670\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4749 - accuracy: 0.8369 - val_loss: 0.3761 - val_accuracy: 0.8683\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4801 - accuracy: 0.8352 - val_loss: 0.3752 - val_accuracy: 0.8678\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4700 - accuracy: 0.8376 - val_loss: 0.3736 - val_accuracy: 0.8681\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4755 - accuracy: 0.8373 - val_loss: 0.3719 - val_accuracy: 0.8686\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4768 - accuracy: 0.8373 - val_loss: 0.3708 - val_accuracy: 0.8691\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4723 - accuracy: 0.8375 - val_loss: 0.3697 - val_accuracy: 0.8698\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4664 - accuracy: 0.8416 - val_loss: 0.3684 - val_accuracy: 0.8700\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4619 - accuracy: 0.8438 - val_loss: 0.3664 - val_accuracy: 0.8708\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4656 - accuracy: 0.8419 - val_loss: 0.3657 - val_accuracy: 0.8705\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4557 - accuracy: 0.8448 - val_loss: 0.3645 - val_accuracy: 0.8706\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4529 - accuracy: 0.8463 - val_loss: 0.3631 - val_accuracy: 0.8725\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4621 - accuracy: 0.8439 - val_loss: 0.3612 - val_accuracy: 0.8729\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4500 - accuracy: 0.8451 - val_loss: 0.3605 - val_accuracy: 0.8730\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4569 - accuracy: 0.8434 - val_loss: 0.3593 - val_accuracy: 0.8734\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4528 - accuracy: 0.8462 - val_loss: 0.3578 - val_accuracy: 0.8743\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4530 - accuracy: 0.8445 - val_loss: 0.3575 - val_accuracy: 0.8737\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4495 - accuracy: 0.8471 - val_loss: 0.3563 - val_accuracy: 0.8751\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4433 - accuracy: 0.8487 - val_loss: 0.3552 - val_accuracy: 0.8754\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4520 - accuracy: 0.8474 - val_loss: 0.3540 - val_accuracy: 0.8754\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4347 - accuracy: 0.8491 - val_loss: 0.3532 - val_accuracy: 0.8761\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4401 - accuracy: 0.8485 - val_loss: 0.3521 - val_accuracy: 0.8770\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4362 - accuracy: 0.8494 - val_loss: 0.3510 - val_accuracy: 0.8779\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4331 - accuracy: 0.8522 - val_loss: 0.3497 - val_accuracy: 0.8779\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4356 - accuracy: 0.8496 - val_loss: 0.3485 - val_accuracy: 0.8781\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4300 - accuracy: 0.8534 - val_loss: 0.3476 - val_accuracy: 0.8786\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4232 - accuracy: 0.8535 - val_loss: 0.3464 - val_accuracy: 0.8796\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4298 - accuracy: 0.8522 - val_loss: 0.3457 - val_accuracy: 0.8798\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4298 - accuracy: 0.8511 - val_loss: 0.3448 - val_accuracy: 0.8793\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4290 - accuracy: 0.8514 - val_loss: 0.3441 - val_accuracy: 0.8803\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4216 - accuracy: 0.8537 - val_loss: 0.3432 - val_accuracy: 0.8812\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4272 - accuracy: 0.8548 - val_loss: 0.3427 - val_accuracy: 0.8815\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4184 - accuracy: 0.8566 - val_loss: 0.3415 - val_accuracy: 0.8811\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4126 - accuracy: 0.8590 - val_loss: 0.3407 - val_accuracy: 0.8815\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4165 - accuracy: 0.8564 - val_loss: 0.3402 - val_accuracy: 0.8818\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4072 - accuracy: 0.8607 - val_loss: 0.3393 - val_accuracy: 0.8823\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4162 - accuracy: 0.8576 - val_loss: 0.3381 - val_accuracy: 0.8826\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4196 - accuracy: 0.8570 - val_loss: 0.3375 - val_accuracy: 0.8830\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4156 - accuracy: 0.8559 - val_loss: 0.3368 - val_accuracy: 0.8827\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4073 - accuracy: 0.8586 - val_loss: 0.3361 - val_accuracy: 0.8830\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4056 - accuracy: 0.8611 - val_loss: 0.3351 - val_accuracy: 0.8834\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4074 - accuracy: 0.8590 - val_loss: 0.3344 - val_accuracy: 0.8836\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4107 - accuracy: 0.8571 - val_loss: 0.3337 - val_accuracy: 0.8837\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4073 - accuracy: 0.8604 - val_loss: 0.3330 - val_accuracy: 0.8837\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4075 - accuracy: 0.8602 - val_loss: 0.3319 - val_accuracy: 0.8836\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4075 - accuracy: 0.8600 - val_loss: 0.3313 - val_accuracy: 0.8840\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4035 - accuracy: 0.8614 - val_loss: 0.3308 - val_accuracy: 0.8840\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3968 - accuracy: 0.8625 - val_loss: 0.3299 - val_accuracy: 0.8843\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3998 - accuracy: 0.8620 - val_loss: 0.3293 - val_accuracy: 0.8847\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4000 - accuracy: 0.8619 - val_loss: 0.3290 - val_accuracy: 0.8844\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3849 - accuracy: 0.8676 - val_loss: 0.3280 - val_accuracy: 0.8840\n",
            "Test_loss 0.32801204919815063\n",
            "Test_accuracy 0.8840000033378601\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}